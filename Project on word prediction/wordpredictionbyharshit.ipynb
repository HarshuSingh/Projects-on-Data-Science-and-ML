{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNMg0iVYGoHp"
      },
      "source": [
        "NEXT WORD PREDICTION PROJECT BY HARSHIT\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzm0xeCGGl0G"
      },
      "source": [
        "import tensorflow as tf\n",
        "import string\n",
        "import requests"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlKLqc1LE0vJ"
      },
      "source": [
        "response=requests.get(\"http://www.gutenberg.org/cache/epub/5200/pg5200.txt\")"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "AK7tN2xtFpBU",
        "outputId": "a41612b2-393f-4957-f8f1-cced58f25cc8"
      },
      "source": [
        "response.text[:1500]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ufeffThe Project Gutenberg EBook of Metamorphosis, by Franz Kafka\\r\\nTranslated by David Wyllie.\\r\\n\\r\\nThis eBook is for the use of anyone anywhere at no cost and with\\r\\nalmost no restrictions whatsoever.  You may copy it, give it away or\\r\\nre-use it under the terms of the Project Gutenberg License included\\r\\nwith this eBook or online at www.gutenberg.org\\r\\n\\r\\n** This is a COPYRIGHTED Project Gutenberg eBook, Details Below **\\r\\n**     Please follow the copyright guidelines in this file.     **\\r\\n\\r\\n\\r\\nTitle: Metamorphosis\\r\\n\\r\\nAuthor: Franz Kafka\\r\\n\\r\\nTranslator: David Wyllie\\r\\n\\r\\nRelease Date: August 16, 2005 [EBook #5200]\\r\\nFirst posted: May 13, 2002\\r\\nLast updated: May 20, 2012\\r\\n\\r\\nLanguage: English\\r\\n\\r\\n\\r\\n*** START OF THIS PROJECT GUTENBERG EBOOK METAMORPHOSIS ***\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nCopyright (C) 2002 David Wyllie.\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n  Metamorphosis\\r\\n  Franz Kafka\\r\\n\\r\\nTranslated by David Wyllie\\r\\n\\r\\n\\r\\n\\r\\nI\\r\\n\\r\\n\\r\\nOne morning, when Gregor Samsa woke from troubled dreams, he found\\r\\nhimself transformed in his bed into a horrible vermin.  He lay on\\r\\nhis armour-like back, and if he lifted his head a little he could\\r\\nsee his brown belly, slightly domed and divided by arches into stiff\\r\\nsections.  The bedding was hardly able to cover it and seemed ready\\r\\nto slide off any moment.  His many legs, pitifully thin compared\\r\\nwith the size of the rest of him, waved about helplessly as he\\r\\nlooked.\\r\\n\\r\\n\"What\\'s happened to me?\" he thought.  It wasn\\'t a dream.  His room,\\r\\na proper human room although a little too small, lay peacefully\\r\\nbetwee'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTcOTqgIGg44"
      },
      "source": [
        "Split the data set into lines\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "akKRrN9sFpLy",
        "outputId": "c7d323a2-538f-4e28-ea4a-767d588a646b"
      },
      "source": [
        "data = response.text.split('\\n')\n",
        "data[0]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ufeffThe Project Gutenberg EBook of Metamorphosis, by Franz Kafka\\r'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "w0kVfs28FpPM",
        "outputId": "3e665719-07f5-45dc-cf2e-44787999ae6f"
      },
      "source": [
        "data = data[253:]\n",
        "data[0]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'away from the bed, bend down with the load and then be patient and\\r'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfcsygFUFpSI",
        "outputId": "31fd7f0b-b95d-401f-ea63-7ec8e82e32af"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2110"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "AfYgEAYDFpVb",
        "outputId": "ccdafc89-7944-433b-d961-62c8b326118e"
      },
      "source": [
        "data = \" \".join(data)\n",
        "data[:1000]\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'away from the bed, bend down with the load and then be patient and\\r careful as he swang over onto the floor, where, hopefully, the\\r little legs would find a use.  Should he really call for help\\r though, even apart from the fact that all the doors were locked?\\r Despite all the difficulty he was in, he could not suppress a smile\\r at this thought.\\r \\r After a while he had already moved so far across that it would have\\r been hard for him to keep his balance if he rocked too hard.  The\\r time was now ten past seven and he would have to make a final\\r decision very soon.  Then there was a ring at the door of the flat.\\r \"That\\'ll be someone from work\", he said to himself, and froze very\\r still, although his little legs only became all the more lively as\\r they danced around.  For a moment everything remained quiet.\\r \"They\\'re not opening the door\", Gregor said to himself, caught in\\r some nonsensical hope.  But then of course, the maid\\'s firm steps\\r went to the door as ever and opened it.  Gregor on'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilehu4QeH1Nz"
      },
      "source": [
        "So here we can see that after passing data to clean_text we get the data in the required format without punctuations and special characters.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLkYQFmGHjdc",
        "outputId": "1f8bef77-22ae-4d99-d414-3b671d3d2f97"
      },
      "source": [
        "def clean_text(doc):\n",
        " tokens = doc.split()\n",
        " table = str.maketrans('', '', string.punctuation)\n",
        " tokens = [w.translate(table) for w in tokens]\n",
        " tokens = [word for word in tokens if word.isalpha()]\n",
        " tokens = [word.lower() for word in tokens]\n",
        " return tokens\n",
        "tokens = clean_text(data)\n",
        "print(tokens[:50])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['away', 'from', 'the', 'bed', 'bend', 'down', 'with', 'the', 'load', 'and', 'then', 'be', 'patient', 'and', 'careful', 'as', 'he', 'swang', 'over', 'onto', 'the', 'floor', 'where', 'hopefully', 'the', 'little', 'legs', 'would', 'find', 'a', 'use', 'should', 'he', 'really', 'call', 'for', 'help', 'though', 'even', 'apart', 'from', 'the', 'fact', 'that', 'all', 'the', 'doors', 'were', 'locked', 'despite']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNoQ78dtHjnm",
        "outputId": "b418c03e-d22e-4216-d7d8-2cbbee9880a8"
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22607"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_67vz0eHjqd",
        "outputId": "829648f0-9a79-455a-a0a4-9cc8f4fcd0fb"
      },
      "source": [
        "length = 50 + 1\n",
        "lines = []\n",
        "for i in range(length, len(tokens)):\n",
        " seq = tokens[i-length:i]\n",
        " line = ' '.join(seq)\n",
        " lines.append(line)\n",
        " if i > 200000:\n",
        "   break\n",
        "print(len(lines))\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J55Pg40dI3O6"
      },
      "source": [
        "Build LSTM Model and Prepare X and y\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIjoJkBtHjtK"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvZSA3hAHjvl"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gVZaRJVHjxz",
        "outputId": "62e06e38-daa6-41a4-a276-6d010d5b4bfe"
      },
      "source": [
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:, :-1], sequences[:,-1]\n",
        "X[0]\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 103,   29,    1,  245, 2883,   98,   14,    1, 1435,    3,   48,\n",
              "         30,  618,    3,  756,   13,    6, 1434,  107,  165,    1,  149,\n",
              "         86, 2880,    1,   78,  225,   21,  530,   12,  156,  193,    6,\n",
              "        142,  754,   17,  180,  116,   49, 1433,   29,    1,  753,   11,\n",
              "         26,    1,  455,   58,  617,  329])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTlxGolOHj0f"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQCDN23pJYxb"
      },
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l8fuskFJY0Q",
        "outputId": "0820a0fe-bdfa-471e-fff3-66108c853fe7"
      },
      "source": [
        "seq_length = X.shape[1]\n",
        "seq_length"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRlHVYz_J0z-"
      },
      "source": [
        "LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzaB6RatJY3S"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLB8vCsgJY5O",
        "outputId": "3a93c27a-c30d-43f1-e910-a04d64fc1c96"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 50, 50)            144250    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50, 100)           60400     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2885)              291385    \n",
            "=================================================================\n",
            "Total params: 586,535\n",
            "Trainable params: 586,535\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhKnT4WrJZn1"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmzhXGi5JZqy",
        "outputId": "a3a83bb7-d98a-4c66-cb26-95e50d57500a"
      },
      "source": [
        "model.fit(X, y, batch_size = 256, epochs = 100)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "89/89 [==============================] - 37s 373ms/step - loss: 6.6391 - accuracy: 0.0496\n",
            "Epoch 2/100\n",
            "89/89 [==============================] - 33s 371ms/step - loss: 6.1889 - accuracy: 0.0540\n",
            "Epoch 3/100\n",
            "89/89 [==============================] - 33s 370ms/step - loss: 6.1645 - accuracy: 0.0540\n",
            "Epoch 4/100\n",
            "89/89 [==============================] - 33s 368ms/step - loss: 6.0556 - accuracy: 0.0540\n",
            "Epoch 5/100\n",
            "89/89 [==============================] - 33s 371ms/step - loss: 5.9206 - accuracy: 0.0557\n",
            "Epoch 6/100\n",
            "89/89 [==============================] - 33s 371ms/step - loss: 5.8009 - accuracy: 0.0575\n",
            "Epoch 7/100\n",
            "89/89 [==============================] - 33s 372ms/step - loss: 5.7255 - accuracy: 0.0606\n",
            "Epoch 8/100\n",
            "89/89 [==============================] - 33s 370ms/step - loss: 5.6665 - accuracy: 0.0660\n",
            "Epoch 9/100\n",
            "89/89 [==============================] - 33s 372ms/step - loss: 5.6145 - accuracy: 0.0709\n",
            "Epoch 10/100\n",
            "89/89 [==============================] - 33s 371ms/step - loss: 5.5670 - accuracy: 0.0737\n",
            "Epoch 11/100\n",
            "89/89 [==============================] - 33s 368ms/step - loss: 5.5212 - accuracy: 0.0802\n",
            "Epoch 12/100\n",
            "89/89 [==============================] - 33s 371ms/step - loss: 5.4736 - accuracy: 0.0832\n",
            "Epoch 13/100\n",
            "89/89 [==============================] - 33s 373ms/step - loss: 5.4211 - accuracy: 0.0873\n",
            "Epoch 14/100\n",
            "89/89 [==============================] - 33s 372ms/step - loss: 5.3577 - accuracy: 0.0912\n",
            "Epoch 15/100\n",
            "89/89 [==============================] - 33s 370ms/step - loss: 5.2856 - accuracy: 0.0966\n",
            "Epoch 16/100\n",
            "89/89 [==============================] - 33s 370ms/step - loss: 5.2180 - accuracy: 0.1045\n",
            "Epoch 17/100\n",
            "89/89 [==============================] - 33s 372ms/step - loss: 5.1540 - accuracy: 0.1094\n",
            "Epoch 18/100\n",
            "89/89 [==============================] - 33s 371ms/step - loss: 5.0924 - accuracy: 0.1162\n",
            "Epoch 19/100\n",
            "89/89 [==============================] - 33s 370ms/step - loss: 5.0290 - accuracy: 0.1207\n",
            "Epoch 20/100\n",
            "89/89 [==============================] - 33s 372ms/step - loss: 4.9738 - accuracy: 0.1228\n",
            "Epoch 21/100\n",
            "89/89 [==============================] - 33s 372ms/step - loss: 4.9215 - accuracy: 0.1278\n",
            "Epoch 22/100\n",
            "89/89 [==============================] - 33s 371ms/step - loss: 4.8747 - accuracy: 0.1331\n",
            "Epoch 23/100\n",
            "89/89 [==============================] - 33s 369ms/step - loss: 4.8277 - accuracy: 0.1355\n",
            "Epoch 24/100\n",
            "89/89 [==============================] - 33s 372ms/step - loss: 4.7855 - accuracy: 0.1389\n",
            "Epoch 25/100\n",
            "89/89 [==============================] - 33s 369ms/step - loss: 4.7433 - accuracy: 0.1399\n",
            "Epoch 26/100\n",
            "89/89 [==============================] - 33s 370ms/step - loss: 4.7055 - accuracy: 0.1427\n",
            "Epoch 27/100\n",
            "89/89 [==============================] - 33s 372ms/step - loss: 4.6713 - accuracy: 0.1469\n",
            "Epoch 28/100\n",
            "89/89 [==============================] - 33s 372ms/step - loss: 4.6328 - accuracy: 0.1488\n",
            "Epoch 29/100\n",
            "89/89 [==============================] - 33s 373ms/step - loss: 4.5959 - accuracy: 0.1499\n",
            "Epoch 30/100\n",
            "89/89 [==============================] - 33s 373ms/step - loss: 4.5626 - accuracy: 0.1528\n",
            "Epoch 31/100\n",
            "89/89 [==============================] - 33s 373ms/step - loss: 4.5268 - accuracy: 0.1542\n",
            "Epoch 32/100\n",
            "89/89 [==============================] - 33s 370ms/step - loss: 4.4900 - accuracy: 0.1594\n",
            "Epoch 33/100\n",
            "89/89 [==============================] - 33s 371ms/step - loss: 4.4527 - accuracy: 0.1600\n",
            "Epoch 34/100\n",
            "89/89 [==============================] - 33s 372ms/step - loss: 4.4058 - accuracy: 0.1655\n",
            "Epoch 35/100\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 4.3592 - accuracy: 0.1653\n",
            "Epoch 36/100\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 4.3208 - accuracy: 0.1676\n",
            "Epoch 37/100\n",
            "89/89 [==============================] - 33s 372ms/step - loss: 4.2815 - accuracy: 0.1699\n",
            "Epoch 38/100\n",
            "89/89 [==============================] - 33s 373ms/step - loss: 4.2481 - accuracy: 0.1715\n",
            "Epoch 39/100\n",
            "89/89 [==============================] - 33s 370ms/step - loss: 4.2160 - accuracy: 0.1757\n",
            "Epoch 40/100\n",
            "89/89 [==============================] - 33s 371ms/step - loss: 4.1827 - accuracy: 0.1754\n",
            "Epoch 41/100\n",
            "89/89 [==============================] - 33s 373ms/step - loss: 4.1599 - accuracy: 0.1780\n",
            "Epoch 42/100\n",
            "89/89 [==============================] - 33s 372ms/step - loss: 4.1249 - accuracy: 0.1823\n",
            "Epoch 43/100\n",
            "89/89 [==============================] - 33s 372ms/step - loss: 4.1975 - accuracy: 0.1783\n",
            "Epoch 44/100\n",
            "89/89 [==============================] - 33s 372ms/step - loss: 4.3136 - accuracy: 0.1684\n",
            "Epoch 45/100\n",
            "89/89 [==============================] - 33s 371ms/step - loss: 4.3204 - accuracy: 0.1703\n",
            "Epoch 46/100\n",
            "89/89 [==============================] - 33s 373ms/step - loss: 4.1922 - accuracy: 0.1780\n",
            "Epoch 47/100\n",
            "89/89 [==============================] - 33s 371ms/step - loss: 4.1243 - accuracy: 0.1808\n",
            "Epoch 48/100\n",
            "89/89 [==============================] - 33s 371ms/step - loss: 4.0628 - accuracy: 0.1832\n",
            "Epoch 49/100\n",
            "89/89 [==============================] - 33s 373ms/step - loss: 4.0097 - accuracy: 0.1853\n",
            "Epoch 50/100\n",
            "89/89 [==============================] - 33s 373ms/step - loss: 3.9661 - accuracy: 0.1913\n",
            "Epoch 51/100\n",
            "89/89 [==============================] - 33s 371ms/step - loss: 3.9225 - accuracy: 0.1937\n",
            "Epoch 52/100\n",
            "89/89 [==============================] - 33s 372ms/step - loss: 3.8797 - accuracy: 0.1972\n",
            "Epoch 53/100\n",
            "89/89 [==============================] - 33s 372ms/step - loss: 3.8388 - accuracy: 0.2016\n",
            "Epoch 54/100\n",
            "89/89 [==============================] - 33s 369ms/step - loss: 3.8027 - accuracy: 0.2035\n",
            "Epoch 55/100\n",
            "89/89 [==============================] - 33s 372ms/step - loss: 3.7696 - accuracy: 0.2070\n",
            "Epoch 56/100\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 3.7285 - accuracy: 0.2109\n",
            "Epoch 57/100\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 3.6900 - accuracy: 0.2145\n",
            "Epoch 58/100\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 3.6514 - accuracy: 0.2177\n",
            "Epoch 59/100\n",
            "89/89 [==============================] - 33s 373ms/step - loss: 3.6225 - accuracy: 0.2246\n",
            "Epoch 60/100\n",
            "89/89 [==============================] - 33s 373ms/step - loss: 3.5882 - accuracy: 0.2278\n",
            "Epoch 61/100\n",
            "89/89 [==============================] - 33s 368ms/step - loss: 3.5520 - accuracy: 0.2300\n",
            "Epoch 62/100\n",
            "89/89 [==============================] - 33s 371ms/step - loss: 3.5156 - accuracy: 0.2342\n",
            "Epoch 63/100\n",
            "89/89 [==============================] - 33s 371ms/step - loss: 3.4755 - accuracy: 0.2367\n",
            "Epoch 64/100\n",
            "89/89 [==============================] - 33s 371ms/step - loss: 3.4488 - accuracy: 0.2439\n",
            "Epoch 65/100\n",
            "89/89 [==============================] - 33s 372ms/step - loss: 3.4141 - accuracy: 0.2458\n",
            "Epoch 66/100\n",
            "89/89 [==============================] - 33s 373ms/step - loss: 3.3784 - accuracy: 0.2520\n",
            "Epoch 67/100\n",
            "89/89 [==============================] - 33s 373ms/step - loss: 3.3472 - accuracy: 0.2570\n",
            "Epoch 68/100\n",
            "89/89 [==============================] - 33s 371ms/step - loss: 3.3389 - accuracy: 0.2593\n",
            "Epoch 69/100\n",
            "89/89 [==============================] - 33s 370ms/step - loss: 3.2973 - accuracy: 0.2637\n",
            "Epoch 70/100\n",
            "89/89 [==============================] - 33s 371ms/step - loss: 3.2681 - accuracy: 0.2703\n",
            "Epoch 71/100\n",
            "89/89 [==============================] - 33s 371ms/step - loss: 3.2312 - accuracy: 0.2726\n",
            "Epoch 72/100\n",
            "89/89 [==============================] - 33s 372ms/step - loss: 3.1934 - accuracy: 0.2788\n",
            "Epoch 73/100\n",
            "89/89 [==============================] - 33s 373ms/step - loss: 3.1627 - accuracy: 0.2833\n",
            "Epoch 74/100\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 3.1277 - accuracy: 0.2889\n",
            "Epoch 75/100\n",
            "89/89 [==============================] - 33s 371ms/step - loss: 3.0992 - accuracy: 0.2913\n",
            "Epoch 76/100\n",
            "89/89 [==============================] - 33s 370ms/step - loss: 3.0717 - accuracy: 0.2996\n",
            "Epoch 77/100\n",
            "89/89 [==============================] - 33s 370ms/step - loss: 3.0441 - accuracy: 0.3039\n",
            "Epoch 78/100\n",
            "89/89 [==============================] - 33s 373ms/step - loss: 3.0111 - accuracy: 0.3104\n",
            "Epoch 79/100\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 2.9807 - accuracy: 0.3161\n",
            "Epoch 80/100\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 3.0228 - accuracy: 0.3133\n",
            "Epoch 81/100\n",
            "89/89 [==============================] - 33s 376ms/step - loss: 3.0296 - accuracy: 0.3132\n",
            "Epoch 82/100\n",
            "89/89 [==============================] - 33s 376ms/step - loss: 3.0103 - accuracy: 0.3171\n",
            "Epoch 83/100\n",
            "89/89 [==============================] - 33s 372ms/step - loss: 2.9525 - accuracy: 0.3242\n",
            "Epoch 84/100\n",
            "89/89 [==============================] - 33s 372ms/step - loss: 2.9508 - accuracy: 0.3218\n",
            "Epoch 85/100\n",
            "89/89 [==============================] - 33s 376ms/step - loss: 2.9043 - accuracy: 0.3315\n",
            "Epoch 86/100\n",
            "89/89 [==============================] - 33s 373ms/step - loss: 2.8871 - accuracy: 0.3369\n",
            "Epoch 87/100\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 2.8549 - accuracy: 0.3417\n",
            "Epoch 88/100\n",
            "89/89 [==============================] - 33s 375ms/step - loss: 2.8193 - accuracy: 0.3468\n",
            "Epoch 89/100\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 2.7929 - accuracy: 0.3515\n",
            "Epoch 90/100\n",
            "89/89 [==============================] - 33s 370ms/step - loss: 2.7620 - accuracy: 0.3554\n",
            "Epoch 91/100\n",
            "89/89 [==============================] - 33s 370ms/step - loss: 2.7502 - accuracy: 0.3619\n",
            "Epoch 92/100\n",
            "89/89 [==============================] - 33s 371ms/step - loss: 2.7102 - accuracy: 0.3689\n",
            "Epoch 93/100\n",
            "89/89 [==============================] - 33s 373ms/step - loss: 2.6928 - accuracy: 0.3715\n",
            "Epoch 94/100\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 2.7047 - accuracy: 0.3691\n",
            "Epoch 95/100\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 2.6917 - accuracy: 0.3763\n",
            "Epoch 96/100\n",
            "89/89 [==============================] - 33s 373ms/step - loss: 2.7561 - accuracy: 0.3695\n",
            "Epoch 97/100\n",
            "89/89 [==============================] - 33s 372ms/step - loss: 2.7576 - accuracy: 0.3718\n",
            "Epoch 98/100\n",
            "89/89 [==============================] - 33s 371ms/step - loss: 2.7022 - accuracy: 0.3791\n",
            "Epoch 99/100\n",
            "89/89 [==============================] - 33s 372ms/step - loss: 2.6498 - accuracy: 0.3836\n",
            "Epoch 100/100\n",
            "89/89 [==============================] - 33s 374ms/step - loss: 2.9088 - accuracy: 0.3516\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe2609a2f90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "jv2ALGG_JZti",
        "outputId": "8d8404df-bba2-4619-d518-addba66dd869"
      },
      "source": [
        "seed_text=lines[12343]\n",
        "seed_text"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'condition seemed serious enough to remind even his father that gregor despite his current sad and revolting form was a family member who could not be treated as an enemy on the contrary as a family there was a duty to swallow any revulsion for him and to be patient just'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUTLO5TIJZv2"
      },
      "source": [
        "def generate_text_seq(model, tokenizer, text_seq_length, seed_text, n_words):\n",
        "  text = []\n",
        "  \n",
        "  for _ in range(n_words):\n",
        "    encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen = text_seq_length, truncating='pre')\n",
        "    y_predict = model.predict_classes(encoded)\n",
        "    predicted_word = ''\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == y_predict:\n",
        "        predicted_word = word\n",
        "        break\n",
        "        seed_text = seed_text + ' ' + predicted_word\n",
        "        text.append(predicted_word)\n",
        "        return ' '.join(text)\n",
        "\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JvCt4dOJZyz",
        "outputId": "63917125-95d3-41d1-b7b6-45a3cfd427c0"
      },
      "source": [
        "generate_text_seq(model, tokenizer, seq_length, seed_text, 100)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSgL8zTZKtvQ"
      },
      "source": [
        "We have got a accuracy of 46%. To increase the accuracy we can increase the number of epochs or we can consider the entire data for training. For this model we have only considered 1/4th of the\n",
        "data for training"
      ]
    }
  ]
}